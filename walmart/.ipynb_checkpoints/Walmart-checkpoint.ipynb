{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv', low_memory=False)\n",
    "test = pd.read_csv('data/test.csv', low_memory=False)\n",
    "\n",
    "featured_train = pd.read_csv('data/grouped_train.csv', low_memory=False)\n",
    "featured_test = pd.read_csv('data/grouped_test.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TripType</th>\n",
       "      <th>VisitNumber</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Upc</th>\n",
       "      <th>ScanCount</th>\n",
       "      <th>DepartmentDescription</th>\n",
       "      <th>FinelineNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "      <td>Friday</td>\n",
       "      <td>68113152929</td>\n",
       "      <td>-1</td>\n",
       "      <td>FINANCIAL SERVICES</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>60538815980</td>\n",
       "      <td>1</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>8931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>7410811099</td>\n",
       "      <td>1</td>\n",
       "      <td>PERSONAL CARE</td>\n",
       "      <td>4504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2238403510</td>\n",
       "      <td>2</td>\n",
       "      <td>PAINT AND ACCESSORIES</td>\n",
       "      <td>3565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2006613744</td>\n",
       "      <td>2</td>\n",
       "      <td>PAINT AND ACCESSORIES</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TripType  VisitNumber Weekday          Upc  ScanCount  \\\n",
       "0       999            5  Friday  68113152929         -1   \n",
       "1        30            7  Friday  60538815980          1   \n",
       "2        30            7  Friday   7410811099          1   \n",
       "3        26            8  Friday   2238403510          2   \n",
       "4        26            8  Friday   2006613744          2   \n",
       "\n",
       "   DepartmentDescription  FinelineNumber  \n",
       "0     FINANCIAL SERVICES            1000  \n",
       "1                  SHOES            8931  \n",
       "2          PERSONAL CARE            4504  \n",
       "3  PAINT AND ACCESSORIES            3565  \n",
       "4  PAINT AND ACCESSORIES            1017  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TripType                   int64\n",
       "VisitNumber                int64\n",
       "Weekday                   object\n",
       "Upc                      float64\n",
       "ScanCount                  int64\n",
       "DepartmentDescription     object\n",
       "FinelineNumber           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/lib/arraysetops.py:198: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/lib/arraysetops.py:251: FutureWarning: numpy equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  return aux[:-1][aux[1:] == aux[:-1]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TripType</th>\n",
       "      <th>VisitNumber</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Upc</th>\n",
       "      <th>ScanCount</th>\n",
       "      <th>DepartmentDescription</th>\n",
       "      <th>FinelineNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>68113152929</td>\n",
       "      <td>-1</td>\n",
       "      <td>21</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>60538815980</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>8931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7410811099</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>4504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TripType  VisitNumber  Weekday          Upc  ScanCount  \\\n",
       "0       999            5        0  68113152929         -1   \n",
       "1        30            7        0  60538815980          1   \n",
       "2        30            7        0   7410811099          1   \n",
       "\n",
       "   DepartmentDescription  FinelineNumber  \n",
       "0                     21            1000  \n",
       "1                     63            8931  \n",
       "2                     51            4504  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace labels with floats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl_enc = LabelEncoder()\n",
    "\n",
    "for c in ['Weekday', 'DepartmentDescription']:\n",
    "    train[c] = lbl_enc.fit_transform(train[c])\n",
    "    test[c] = lbl_enc.transform(test[c])\n",
    "    \n",
    "train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show unique department descriptions\n",
    "departments = np.sort(train.DepartmentDescription.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_features(data):\n",
    "    for dep in departments:\n",
    "        data['Department_' + str(dep)] = 0\n",
    "        \n",
    "    for index, row in data.iterrows():\n",
    "        data.loc[index, 'Department_' + str(int(row.DepartmentDescription))] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "build_features(train)\n",
    "build_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_tr = list(train.columns)\n",
    "[cols_tr.remove(c) for c in ['Weekday', 'DepartmentDescription', 'Upc', 'FinelineNumber']]\n",
    "cols_te = list(train.columns)\n",
    "[cols_te.remove(c) for c in ['Weekday', 'TripType', 'DepartmentDescription', 'Upc', 'FinelineNumber']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featured_train = train[cols_tr].groupby(['VisitNumber', 'TripType']).sum().reset_index()\n",
    "featured_test = test[cols_te].groupby(['VisitNumber']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = list(featured_train.columns)\n",
    "cols.remove('VisitNumber')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiclass_log_loss(clf, y_true, y_pred, eps=1e-15):\n",
    "    Y_true = ycv.apply(lambda x: np.where(rf.classes_==x)[0][0]).values\n",
    "    predictions = np.clip(y_pred, eps, 1 - eps)\n",
    "\n",
    "    # normalize row sums to 1\n",
    "    predictions /= predictions.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    actual = np.zeros(y_pred.shape)\n",
    "    rows = actual.shape[0]\n",
    "    actual[np.arange(rows), Y_true.astype(int)] = 1\n",
    "    vsota = np.sum(actual * np.log(predictions))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "xtrain, xcv, ytrain, ycv = train_test_split(featured_train[cols[1:]], featured_train['TripType'], test_size = 0.052,  random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Try Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    max_features=16,\n",
    "    n_jobs=2,\n",
    "    oob_score=True\n",
    ")\n",
    "rf.fit(xtrain, ytrain)\n",
    "predictionRF = rf.predict_proba(xcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2526831494360087"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_log_loss(rf, ycv, predictionRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score is: 1.2526831494360087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Try Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    solver='lbfgs',\n",
    "    multi_class='multinomial'\n",
    ")\n",
    "\n",
    "lr.fit(xtrain, ytrain)\n",
    "predictionLR = lr.predict_proba(xcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4526601797370922"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_log_loss(lr, ycv, predictionLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Try XGBoost multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set params\n",
    "\n",
    "params = {\"objective\": \"multi:softprob\",\n",
    "          #\"booster\": \"gbtree\",\n",
    "          \"eta\": 0.1,\n",
    "          \"max_depth\": 5,\n",
    "          \"subsample\": 0.7,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"silent\": 1,\n",
    "          \"num_class\": 38,\n",
    "          \"eval_metric\": 'mlogloss'\n",
    "          }\n",
    "num_trees = 500\n",
    "stop = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.sort(ytrain.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ytrain_labeled = pd.Series([np.where(labels==x)[0][0] for x in ytrain])\n",
    "ycv_labeled = pd.Series([np.where(labels==x)[0][0] for x in ycv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until train error hasn't decreased in 20 rounds.\n",
      "[0]\teval-mlogloss:3.060632\ttrain-mlogloss:3.048442\n",
      "[1]\teval-mlogloss:2.733049\ttrain-mlogloss:2.718265\n",
      "[2]\teval-mlogloss:2.542099\ttrain-mlogloss:2.524906\n",
      "[3]\teval-mlogloss:2.373853\ttrain-mlogloss:2.356514\n",
      "[4]\teval-mlogloss:2.252983\ttrain-mlogloss:2.232906\n",
      "[5]\teval-mlogloss:2.144183\ttrain-mlogloss:2.122234\n",
      "[6]\teval-mlogloss:2.054298\ttrain-mlogloss:2.030032\n",
      "[7]\teval-mlogloss:1.970899\ttrain-mlogloss:1.943988\n",
      "[8]\teval-mlogloss:1.900977\ttrain-mlogloss:1.872876\n",
      "[9]\teval-mlogloss:1.829679\ttrain-mlogloss:1.799765\n",
      "[10]\teval-mlogloss:1.767051\ttrain-mlogloss:1.735574\n",
      "[11]\teval-mlogloss:1.713817\ttrain-mlogloss:1.681560\n",
      "[12]\teval-mlogloss:1.665678\ttrain-mlogloss:1.631624\n",
      "[13]\teval-mlogloss:1.621144\ttrain-mlogloss:1.585907\n",
      "[14]\teval-mlogloss:1.580132\ttrain-mlogloss:1.543851\n",
      "[15]\teval-mlogloss:1.542087\ttrain-mlogloss:1.505094\n",
      "[16]\teval-mlogloss:1.506959\ttrain-mlogloss:1.468696\n",
      "[17]\teval-mlogloss:1.472891\ttrain-mlogloss:1.433193\n",
      "[18]\teval-mlogloss:1.442585\ttrain-mlogloss:1.402572\n",
      "[19]\teval-mlogloss:1.417775\ttrain-mlogloss:1.376914\n",
      "[20]\teval-mlogloss:1.392381\ttrain-mlogloss:1.351228\n",
      "[21]\teval-mlogloss:1.369325\ttrain-mlogloss:1.326879\n",
      "[22]\teval-mlogloss:1.349082\ttrain-mlogloss:1.305519\n",
      "[23]\teval-mlogloss:1.329763\ttrain-mlogloss:1.285011\n",
      "[24]\teval-mlogloss:1.312427\ttrain-mlogloss:1.266428\n",
      "[25]\teval-mlogloss:1.293409\ttrain-mlogloss:1.246417\n",
      "[26]\teval-mlogloss:1.275921\ttrain-mlogloss:1.227862\n",
      "[27]\teval-mlogloss:1.259199\ttrain-mlogloss:1.209936\n",
      "[28]\teval-mlogloss:1.243760\ttrain-mlogloss:1.193447\n",
      "[29]\teval-mlogloss:1.228891\ttrain-mlogloss:1.177965\n",
      "[30]\teval-mlogloss:1.215219\ttrain-mlogloss:1.163221\n",
      "[31]\teval-mlogloss:1.202778\ttrain-mlogloss:1.150025\n",
      "[32]\teval-mlogloss:1.190736\ttrain-mlogloss:1.137575\n",
      "[33]\teval-mlogloss:1.178925\ttrain-mlogloss:1.125085\n",
      "[34]\teval-mlogloss:1.168092\ttrain-mlogloss:1.113485\n",
      "[35]\teval-mlogloss:1.157088\ttrain-mlogloss:1.101949\n",
      "[36]\teval-mlogloss:1.147516\ttrain-mlogloss:1.091793\n",
      "[37]\teval-mlogloss:1.139208\ttrain-mlogloss:1.082460\n",
      "[38]\teval-mlogloss:1.129863\ttrain-mlogloss:1.072281\n",
      "[39]\teval-mlogloss:1.122095\ttrain-mlogloss:1.063555\n",
      "[40]\teval-mlogloss:1.114200\ttrain-mlogloss:1.054460\n",
      "[41]\teval-mlogloss:1.107096\ttrain-mlogloss:1.046640\n",
      "[42]\teval-mlogloss:1.099129\ttrain-mlogloss:1.037829\n",
      "[43]\teval-mlogloss:1.092038\ttrain-mlogloss:1.029988\n",
      "[44]\teval-mlogloss:1.085271\ttrain-mlogloss:1.022540\n",
      "[45]\teval-mlogloss:1.079183\ttrain-mlogloss:1.015781\n",
      "[46]\teval-mlogloss:1.073126\ttrain-mlogloss:1.008880\n",
      "[47]\teval-mlogloss:1.067578\ttrain-mlogloss:1.002282\n",
      "[48]\teval-mlogloss:1.061859\ttrain-mlogloss:0.995728\n",
      "[49]\teval-mlogloss:1.056568\ttrain-mlogloss:0.989821\n",
      "[50]\teval-mlogloss:1.051032\ttrain-mlogloss:0.983764\n",
      "[51]\teval-mlogloss:1.046122\ttrain-mlogloss:0.978130\n",
      "[52]\teval-mlogloss:1.041569\ttrain-mlogloss:0.972853\n",
      "[53]\teval-mlogloss:1.037370\ttrain-mlogloss:0.967972\n",
      "[54]\teval-mlogloss:1.033233\ttrain-mlogloss:0.963012\n",
      "[55]\teval-mlogloss:1.029061\ttrain-mlogloss:0.957828\n",
      "[56]\teval-mlogloss:1.025270\ttrain-mlogloss:0.953150\n",
      "[57]\teval-mlogloss:1.021448\ttrain-mlogloss:0.948451\n",
      "[58]\teval-mlogloss:1.018056\ttrain-mlogloss:0.944226\n",
      "[59]\teval-mlogloss:1.014804\ttrain-mlogloss:0.940046\n",
      "[60]\teval-mlogloss:1.011351\ttrain-mlogloss:0.935748\n",
      "[61]\teval-mlogloss:1.008253\ttrain-mlogloss:0.931588\n",
      "[62]\teval-mlogloss:1.005251\ttrain-mlogloss:0.927767\n",
      "[63]\teval-mlogloss:1.002287\ttrain-mlogloss:0.924037\n",
      "[64]\teval-mlogloss:0.999207\ttrain-mlogloss:0.920330\n",
      "[65]\teval-mlogloss:0.996336\ttrain-mlogloss:0.916925\n",
      "[66]\teval-mlogloss:0.993770\ttrain-mlogloss:0.913623\n",
      "[67]\teval-mlogloss:0.990920\ttrain-mlogloss:0.909972\n",
      "[68]\teval-mlogloss:0.988572\ttrain-mlogloss:0.907013\n",
      "[69]\teval-mlogloss:0.986037\ttrain-mlogloss:0.903815\n",
      "[70]\teval-mlogloss:0.983596\ttrain-mlogloss:0.900713\n",
      "[71]\teval-mlogloss:0.981056\ttrain-mlogloss:0.897731\n",
      "[72]\teval-mlogloss:0.978900\ttrain-mlogloss:0.894739\n",
      "[73]\teval-mlogloss:0.976479\ttrain-mlogloss:0.891768\n",
      "[74]\teval-mlogloss:0.974633\ttrain-mlogloss:0.889045\n",
      "[75]\teval-mlogloss:0.972468\ttrain-mlogloss:0.886241\n",
      "[76]\teval-mlogloss:0.970863\ttrain-mlogloss:0.883811\n",
      "[77]\teval-mlogloss:0.968950\ttrain-mlogloss:0.881109\n",
      "[78]\teval-mlogloss:0.967097\ttrain-mlogloss:0.878507\n",
      "[79]\teval-mlogloss:0.965461\ttrain-mlogloss:0.876120\n",
      "[80]\teval-mlogloss:0.963634\ttrain-mlogloss:0.873824\n",
      "[81]\teval-mlogloss:0.961864\ttrain-mlogloss:0.871467\n",
      "[82]\teval-mlogloss:0.960171\ttrain-mlogloss:0.869218\n",
      "[83]\teval-mlogloss:0.958345\ttrain-mlogloss:0.866903\n",
      "[84]\teval-mlogloss:0.956828\ttrain-mlogloss:0.864652\n",
      "[85]\teval-mlogloss:0.955281\ttrain-mlogloss:0.862510\n",
      "[86]\teval-mlogloss:0.953623\ttrain-mlogloss:0.860452\n",
      "[87]\teval-mlogloss:0.952159\ttrain-mlogloss:0.858374\n",
      "[88]\teval-mlogloss:0.950713\ttrain-mlogloss:0.856305\n",
      "[89]\teval-mlogloss:0.949738\ttrain-mlogloss:0.854501\n",
      "[90]\teval-mlogloss:0.948382\ttrain-mlogloss:0.852327\n",
      "[91]\teval-mlogloss:0.947257\ttrain-mlogloss:0.850334\n",
      "[92]\teval-mlogloss:0.946099\ttrain-mlogloss:0.848449\n",
      "[93]\teval-mlogloss:0.944916\ttrain-mlogloss:0.846650\n",
      "[94]\teval-mlogloss:0.943889\ttrain-mlogloss:0.844889\n",
      "[95]\teval-mlogloss:0.942815\ttrain-mlogloss:0.843041\n",
      "[96]\teval-mlogloss:0.941647\ttrain-mlogloss:0.841362\n",
      "[97]\teval-mlogloss:0.940529\ttrain-mlogloss:0.839561\n",
      "[98]\teval-mlogloss:0.939308\ttrain-mlogloss:0.837882\n",
      "[99]\teval-mlogloss:0.938207\ttrain-mlogloss:0.836110\n",
      "[100]\teval-mlogloss:0.937297\ttrain-mlogloss:0.834508\n",
      "[101]\teval-mlogloss:0.936238\ttrain-mlogloss:0.832671\n",
      "[102]\teval-mlogloss:0.935244\ttrain-mlogloss:0.831079\n",
      "[103]\teval-mlogloss:0.934486\ttrain-mlogloss:0.829544\n",
      "[104]\teval-mlogloss:0.933495\ttrain-mlogloss:0.828083\n",
      "[105]\teval-mlogloss:0.932367\ttrain-mlogloss:0.826613\n",
      "[106]\teval-mlogloss:0.931406\ttrain-mlogloss:0.825105\n",
      "[107]\teval-mlogloss:0.930572\ttrain-mlogloss:0.823675\n",
      "[108]\teval-mlogloss:0.929837\ttrain-mlogloss:0.822273\n",
      "[109]\teval-mlogloss:0.929097\ttrain-mlogloss:0.820896\n",
      "[110]\teval-mlogloss:0.928290\ttrain-mlogloss:0.819595\n",
      "[111]\teval-mlogloss:0.927352\ttrain-mlogloss:0.818101\n",
      "[112]\teval-mlogloss:0.926480\ttrain-mlogloss:0.816668\n",
      "[113]\teval-mlogloss:0.925719\ttrain-mlogloss:0.815262\n",
      "[114]\teval-mlogloss:0.924916\ttrain-mlogloss:0.813829\n",
      "[115]\teval-mlogloss:0.924171\ttrain-mlogloss:0.812498\n",
      "[116]\teval-mlogloss:0.923535\ttrain-mlogloss:0.811218\n",
      "[117]\teval-mlogloss:0.922913\ttrain-mlogloss:0.809959\n",
      "[118]\teval-mlogloss:0.922296\ttrain-mlogloss:0.808691\n",
      "[119]\teval-mlogloss:0.921570\ttrain-mlogloss:0.807515\n",
      "[120]\teval-mlogloss:0.920919\ttrain-mlogloss:0.806275\n",
      "[121]\teval-mlogloss:0.920356\ttrain-mlogloss:0.805075\n",
      "[122]\teval-mlogloss:0.919653\ttrain-mlogloss:0.803988\n",
      "[123]\teval-mlogloss:0.919065\ttrain-mlogloss:0.802868\n",
      "[124]\teval-mlogloss:0.918420\ttrain-mlogloss:0.801666\n",
      "[125]\teval-mlogloss:0.917762\ttrain-mlogloss:0.800496\n",
      "[126]\teval-mlogloss:0.917134\ttrain-mlogloss:0.799307\n",
      "[127]\teval-mlogloss:0.916505\ttrain-mlogloss:0.798177\n",
      "[128]\teval-mlogloss:0.915973\ttrain-mlogloss:0.797108\n",
      "[129]\teval-mlogloss:0.915329\ttrain-mlogloss:0.796051\n",
      "[130]\teval-mlogloss:0.914910\ttrain-mlogloss:0.794987\n",
      "[131]\teval-mlogloss:0.914364\ttrain-mlogloss:0.793784\n",
      "[132]\teval-mlogloss:0.913757\ttrain-mlogloss:0.792695\n",
      "[133]\teval-mlogloss:0.913176\ttrain-mlogloss:0.791641\n",
      "[134]\teval-mlogloss:0.912429\ttrain-mlogloss:0.790664\n",
      "[135]\teval-mlogloss:0.911920\ttrain-mlogloss:0.789662\n",
      "[136]\teval-mlogloss:0.911329\ttrain-mlogloss:0.788620\n",
      "[137]\teval-mlogloss:0.910680\ttrain-mlogloss:0.787527\n",
      "[138]\teval-mlogloss:0.910214\ttrain-mlogloss:0.786602\n",
      "[139]\teval-mlogloss:0.909725\ttrain-mlogloss:0.785644\n",
      "[140]\teval-mlogloss:0.908955\ttrain-mlogloss:0.784622\n",
      "[141]\teval-mlogloss:0.908493\ttrain-mlogloss:0.783675\n",
      "[142]\teval-mlogloss:0.908092\ttrain-mlogloss:0.782721\n",
      "[143]\teval-mlogloss:0.907534\ttrain-mlogloss:0.781782\n",
      "[144]\teval-mlogloss:0.907035\ttrain-mlogloss:0.780753\n",
      "[145]\teval-mlogloss:0.906533\ttrain-mlogloss:0.779758\n",
      "[146]\teval-mlogloss:0.905961\ttrain-mlogloss:0.778866\n",
      "[147]\teval-mlogloss:0.905546\ttrain-mlogloss:0.777946\n",
      "[148]\teval-mlogloss:0.905070\ttrain-mlogloss:0.776999\n",
      "[149]\teval-mlogloss:0.904557\ttrain-mlogloss:0.776017\n",
      "[150]\teval-mlogloss:0.904096\ttrain-mlogloss:0.775027\n",
      "[151]\teval-mlogloss:0.903657\ttrain-mlogloss:0.774152\n",
      "[152]\teval-mlogloss:0.903349\ttrain-mlogloss:0.773278\n",
      "[153]\teval-mlogloss:0.902948\ttrain-mlogloss:0.772320\n",
      "[154]\teval-mlogloss:0.902546\ttrain-mlogloss:0.771450\n",
      "[155]\teval-mlogloss:0.902148\ttrain-mlogloss:0.770651\n",
      "[156]\teval-mlogloss:0.901743\ttrain-mlogloss:0.769817\n",
      "[157]\teval-mlogloss:0.901382\ttrain-mlogloss:0.768919\n",
      "[158]\teval-mlogloss:0.900911\ttrain-mlogloss:0.768047\n",
      "[159]\teval-mlogloss:0.900421\ttrain-mlogloss:0.767259\n",
      "[160]\teval-mlogloss:0.899855\ttrain-mlogloss:0.766270\n",
      "[161]\teval-mlogloss:0.899594\ttrain-mlogloss:0.765440\n",
      "[162]\teval-mlogloss:0.899112\ttrain-mlogloss:0.764672\n",
      "[163]\teval-mlogloss:0.898709\ttrain-mlogloss:0.763840\n",
      "[164]\teval-mlogloss:0.898393\ttrain-mlogloss:0.762894\n",
      "[165]\teval-mlogloss:0.897954\ttrain-mlogloss:0.762077\n",
      "[166]\teval-mlogloss:0.897569\ttrain-mlogloss:0.761270\n",
      "[167]\teval-mlogloss:0.897171\ttrain-mlogloss:0.760534\n",
      "[168]\teval-mlogloss:0.896872\ttrain-mlogloss:0.759784\n",
      "[169]\teval-mlogloss:0.896582\ttrain-mlogloss:0.758970\n",
      "[170]\teval-mlogloss:0.896186\ttrain-mlogloss:0.758152\n",
      "[171]\teval-mlogloss:0.895869\ttrain-mlogloss:0.757455\n",
      "[172]\teval-mlogloss:0.895577\ttrain-mlogloss:0.756667\n",
      "[173]\teval-mlogloss:0.895423\ttrain-mlogloss:0.755950\n",
      "[174]\teval-mlogloss:0.895179\ttrain-mlogloss:0.755118\n",
      "[175]\teval-mlogloss:0.894888\ttrain-mlogloss:0.754355\n",
      "[176]\teval-mlogloss:0.894603\ttrain-mlogloss:0.753625\n",
      "[177]\teval-mlogloss:0.894376\ttrain-mlogloss:0.752868\n",
      "[178]\teval-mlogloss:0.893976\ttrain-mlogloss:0.752125\n",
      "[179]\teval-mlogloss:0.893707\ttrain-mlogloss:0.751385\n",
      "[180]\teval-mlogloss:0.893225\ttrain-mlogloss:0.750580\n",
      "[181]\teval-mlogloss:0.892953\ttrain-mlogloss:0.749858\n",
      "[182]\teval-mlogloss:0.892587\ttrain-mlogloss:0.749128\n",
      "[183]\teval-mlogloss:0.892312\ttrain-mlogloss:0.748479\n",
      "[184]\teval-mlogloss:0.892005\ttrain-mlogloss:0.747800\n",
      "[185]\teval-mlogloss:0.891576\ttrain-mlogloss:0.747070\n",
      "[186]\teval-mlogloss:0.891289\ttrain-mlogloss:0.746361\n",
      "[187]\teval-mlogloss:0.891100\ttrain-mlogloss:0.745621\n",
      "[188]\teval-mlogloss:0.890778\ttrain-mlogloss:0.744863\n",
      "[189]\teval-mlogloss:0.890405\ttrain-mlogloss:0.744082\n",
      "[190]\teval-mlogloss:0.890150\ttrain-mlogloss:0.743420\n",
      "[191]\teval-mlogloss:0.889846\ttrain-mlogloss:0.742754\n",
      "[192]\teval-mlogloss:0.889601\ttrain-mlogloss:0.742058\n",
      "[193]\teval-mlogloss:0.889366\ttrain-mlogloss:0.741415\n",
      "[194]\teval-mlogloss:0.889063\ttrain-mlogloss:0.740772\n",
      "[195]\teval-mlogloss:0.888754\ttrain-mlogloss:0.740099\n",
      "[196]\teval-mlogloss:0.888493\ttrain-mlogloss:0.739394\n",
      "[197]\teval-mlogloss:0.888122\ttrain-mlogloss:0.738767\n",
      "[198]\teval-mlogloss:0.887829\ttrain-mlogloss:0.738074\n",
      "[199]\teval-mlogloss:0.887649\ttrain-mlogloss:0.737471\n",
      "[200]\teval-mlogloss:0.887284\ttrain-mlogloss:0.736742\n",
      "[201]\teval-mlogloss:0.886977\ttrain-mlogloss:0.736059\n",
      "[202]\teval-mlogloss:0.886818\ttrain-mlogloss:0.735408\n",
      "[203]\teval-mlogloss:0.886454\ttrain-mlogloss:0.734784\n",
      "[204]\teval-mlogloss:0.886290\ttrain-mlogloss:0.734180\n",
      "[205]\teval-mlogloss:0.886029\ttrain-mlogloss:0.733542\n",
      "[206]\teval-mlogloss:0.885830\ttrain-mlogloss:0.732967\n",
      "[207]\teval-mlogloss:0.885485\ttrain-mlogloss:0.732222\n",
      "[208]\teval-mlogloss:0.885248\ttrain-mlogloss:0.731615\n",
      "[209]\teval-mlogloss:0.885033\ttrain-mlogloss:0.730885\n",
      "[210]\teval-mlogloss:0.884769\ttrain-mlogloss:0.730292\n",
      "[211]\teval-mlogloss:0.884437\ttrain-mlogloss:0.729704\n",
      "[212]\teval-mlogloss:0.884323\ttrain-mlogloss:0.729122\n",
      "[213]\teval-mlogloss:0.884200\ttrain-mlogloss:0.728449\n",
      "[214]\teval-mlogloss:0.884114\ttrain-mlogloss:0.727812\n",
      "[215]\teval-mlogloss:0.884015\ttrain-mlogloss:0.727120\n",
      "[216]\teval-mlogloss:0.883783\ttrain-mlogloss:0.726511\n",
      "[217]\teval-mlogloss:0.883620\ttrain-mlogloss:0.725837\n",
      "[218]\teval-mlogloss:0.883483\ttrain-mlogloss:0.725198\n",
      "[219]\teval-mlogloss:0.883222\ttrain-mlogloss:0.724644\n",
      "[220]\teval-mlogloss:0.883054\ttrain-mlogloss:0.724041\n",
      "[221]\teval-mlogloss:0.882990\ttrain-mlogloss:0.723413\n",
      "[222]\teval-mlogloss:0.882751\ttrain-mlogloss:0.722768\n",
      "[223]\teval-mlogloss:0.882603\ttrain-mlogloss:0.722203\n",
      "[224]\teval-mlogloss:0.882387\ttrain-mlogloss:0.721696\n",
      "[225]\teval-mlogloss:0.882298\ttrain-mlogloss:0.721170\n",
      "[226]\teval-mlogloss:0.881964\ttrain-mlogloss:0.720587\n",
      "[227]\teval-mlogloss:0.881769\ttrain-mlogloss:0.720026\n",
      "[228]\teval-mlogloss:0.881595\ttrain-mlogloss:0.719430\n",
      "[229]\teval-mlogloss:0.881461\ttrain-mlogloss:0.718817\n",
      "[230]\teval-mlogloss:0.881292\ttrain-mlogloss:0.718244\n",
      "[231]\teval-mlogloss:0.881112\ttrain-mlogloss:0.717629\n",
      "[232]\teval-mlogloss:0.880954\ttrain-mlogloss:0.717052\n",
      "[233]\teval-mlogloss:0.880813\ttrain-mlogloss:0.716540\n",
      "[234]\teval-mlogloss:0.880675\ttrain-mlogloss:0.715892\n",
      "[235]\teval-mlogloss:0.880597\ttrain-mlogloss:0.715323\n",
      "[236]\teval-mlogloss:0.880449\ttrain-mlogloss:0.714805\n",
      "[237]\teval-mlogloss:0.880360\ttrain-mlogloss:0.714187\n",
      "[238]\teval-mlogloss:0.880121\ttrain-mlogloss:0.713638\n",
      "[239]\teval-mlogloss:0.879998\ttrain-mlogloss:0.713171\n",
      "[240]\teval-mlogloss:0.879827\ttrain-mlogloss:0.712652\n",
      "[241]\teval-mlogloss:0.879636\ttrain-mlogloss:0.712128\n",
      "[242]\teval-mlogloss:0.879442\ttrain-mlogloss:0.711548\n",
      "[243]\teval-mlogloss:0.879275\ttrain-mlogloss:0.710996\n",
      "[244]\teval-mlogloss:0.879098\ttrain-mlogloss:0.710488\n",
      "[245]\teval-mlogloss:0.878807\ttrain-mlogloss:0.709848\n",
      "[246]\teval-mlogloss:0.878745\ttrain-mlogloss:0.709402\n",
      "[247]\teval-mlogloss:0.878486\ttrain-mlogloss:0.708888\n",
      "[248]\teval-mlogloss:0.878382\ttrain-mlogloss:0.708279\n",
      "[249]\teval-mlogloss:0.878322\ttrain-mlogloss:0.707697\n",
      "[250]\teval-mlogloss:0.878216\ttrain-mlogloss:0.707131\n",
      "[251]\teval-mlogloss:0.878126\ttrain-mlogloss:0.706608\n",
      "[252]\teval-mlogloss:0.877926\ttrain-mlogloss:0.706028\n",
      "[253]\teval-mlogloss:0.877709\ttrain-mlogloss:0.705461\n",
      "[254]\teval-mlogloss:0.877627\ttrain-mlogloss:0.705031\n",
      "[255]\teval-mlogloss:0.877451\ttrain-mlogloss:0.704549\n",
      "[256]\teval-mlogloss:0.877338\ttrain-mlogloss:0.704057\n",
      "[257]\teval-mlogloss:0.877064\ttrain-mlogloss:0.703605\n",
      "[258]\teval-mlogloss:0.876939\ttrain-mlogloss:0.703084\n",
      "[259]\teval-mlogloss:0.876722\ttrain-mlogloss:0.702609\n",
      "[260]\teval-mlogloss:0.876696\ttrain-mlogloss:0.702121\n",
      "[261]\teval-mlogloss:0.876607\ttrain-mlogloss:0.701599\n",
      "[262]\teval-mlogloss:0.876469\ttrain-mlogloss:0.701102\n",
      "[263]\teval-mlogloss:0.876309\ttrain-mlogloss:0.700568\n",
      "[264]\teval-mlogloss:0.876032\ttrain-mlogloss:0.699993\n",
      "[265]\teval-mlogloss:0.875858\ttrain-mlogloss:0.699506\n",
      "[266]\teval-mlogloss:0.875818\ttrain-mlogloss:0.699024\n",
      "[267]\teval-mlogloss:0.875719\ttrain-mlogloss:0.698481\n",
      "[268]\teval-mlogloss:0.875556\ttrain-mlogloss:0.698030\n",
      "[269]\teval-mlogloss:0.875416\ttrain-mlogloss:0.697517\n",
      "[270]\teval-mlogloss:0.875359\ttrain-mlogloss:0.697029\n",
      "[271]\teval-mlogloss:0.875313\ttrain-mlogloss:0.696514\n",
      "[272]\teval-mlogloss:0.875106\ttrain-mlogloss:0.695992\n",
      "[273]\teval-mlogloss:0.874959\ttrain-mlogloss:0.695525\n",
      "[274]\teval-mlogloss:0.874867\ttrain-mlogloss:0.695013\n",
      "[275]\teval-mlogloss:0.874796\ttrain-mlogloss:0.694555\n",
      "[276]\teval-mlogloss:0.874730\ttrain-mlogloss:0.694077\n",
      "[277]\teval-mlogloss:0.874652\ttrain-mlogloss:0.693630\n",
      "[278]\teval-mlogloss:0.874622\ttrain-mlogloss:0.693146\n",
      "[279]\teval-mlogloss:0.874530\ttrain-mlogloss:0.692657\n",
      "[280]\teval-mlogloss:0.874445\ttrain-mlogloss:0.692201\n",
      "[281]\teval-mlogloss:0.874366\ttrain-mlogloss:0.691786\n",
      "[282]\teval-mlogloss:0.874295\ttrain-mlogloss:0.691262\n",
      "[283]\teval-mlogloss:0.874258\ttrain-mlogloss:0.690776\n",
      "[284]\teval-mlogloss:0.874162\ttrain-mlogloss:0.690329\n",
      "[285]\teval-mlogloss:0.874113\ttrain-mlogloss:0.689855\n",
      "[286]\teval-mlogloss:0.874081\ttrain-mlogloss:0.689387\n",
      "[287]\teval-mlogloss:0.874139\ttrain-mlogloss:0.688888\n",
      "[288]\teval-mlogloss:0.874076\ttrain-mlogloss:0.688424\n",
      "[289]\teval-mlogloss:0.874028\ttrain-mlogloss:0.688007\n",
      "[290]\teval-mlogloss:0.873988\ttrain-mlogloss:0.687501\n",
      "[291]\teval-mlogloss:0.873895\ttrain-mlogloss:0.687086\n",
      "[292]\teval-mlogloss:0.873822\ttrain-mlogloss:0.686653\n",
      "[293]\teval-mlogloss:0.873664\ttrain-mlogloss:0.686186\n",
      "[294]\teval-mlogloss:0.873669\ttrain-mlogloss:0.685771\n",
      "[295]\teval-mlogloss:0.873730\ttrain-mlogloss:0.685311\n",
      "[296]\teval-mlogloss:0.873687\ttrain-mlogloss:0.684837\n",
      "[297]\teval-mlogloss:0.873641\ttrain-mlogloss:0.684443\n",
      "[298]\teval-mlogloss:0.873602\ttrain-mlogloss:0.684037\n",
      "[299]\teval-mlogloss:0.873472\ttrain-mlogloss:0.683586\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "dtrain = xgb.DMatrix(xtrain.as_matrix(), label=ytrain_labeled)\n",
    "dvalid = xgb.DMatrix(xcv.as_matrix(), label=ycv_labeled)\n",
    "watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, early_stopping_rounds=stop, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The best score is:** 0.873472"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict classes probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. With RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=250,\n",
    "    max_depth=20,\n",
    "    max_features=16,\n",
    "    # n_jobs=2,\n",
    "    oob_score=True\n",
    ")\n",
    "rf.fit(featured_train[cols], featured_train['TripType'])\n",
    "submitRF = rf.predict_proba(featured_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.47336322e-05,   0.00000000e+00,   2.28909884e-04, ...,\n",
       "          2.09900422e-03,   1.47259690e-03,   1.31402960e-02],\n",
       "       [  2.36784164e-03,   7.34320380e-04,   1.58061994e-02, ...,\n",
       "          1.96299542e-02,   5.01692983e-03,   1.39586652e-02],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   3.05188199e-05, ...,\n",
       "          2.66920877e-05,   1.71591992e-05,   9.75645995e-01],\n",
       "       ..., \n",
       "       [  5.03898222e-02,   2.12782057e-04,   5.36054290e-03, ...,\n",
       "          1.45702693e-04,   5.26427125e-05,   3.88865881e-02],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   2.21086773e-04, ...,\n",
       "          7.42077791e-03,   2.72459177e-02,   2.88190941e-03],\n",
       "       [  1.09909018e-05,   4.05482709e-04,   2.61374524e-03, ...,\n",
       "          3.88168257e-03,   6.54779274e-03,   3.77339845e-03]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_columns = list(featured_test.columns)\n",
    "test_columns.remove('VisitNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(featured_test[test_columns].as_matrix())\n",
    "test_probs = gbm.predict(dtest)\n",
    "indices = test_probs < 0\n",
    "test_probs[indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit_XGB = test_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.20367549e-05,   4.27226769e-06,   1.45024285e-04, ...,\n",
       "          2.91725248e-03,   5.21892798e-04,   2.45908406e-02],\n",
       "       [  5.25757168e-05,   2.38046650e-05,   2.99324805e-04, ...,\n",
       "          5.44686150e-03,   2.41568676e-04,   7.46783568e-03],\n",
       "       [  1.99037615e-07,   9.66535794e-08,   2.67540440e-06, ...,\n",
       "          5.93166874e-07,   1.36867095e-06,   9.99633312e-01],\n",
       "       ..., \n",
       "       [  1.75808999e-03,   2.70718810e-05,   4.62111580e-04, ...,\n",
       "          1.00745805e-04,   7.68516766e-05,   4.32697423e-02],\n",
       "       [  4.70975465e-06,   9.00235648e-07,   3.46708184e-05, ...,\n",
       "          1.36217745e-02,   1.56321861e-02,   1.19461806e-03],\n",
       "       [  9.24449807e-07,   1.71101945e-07,   1.25795327e-06, ...,\n",
       "          1.67042471e-03,   4.71482461e-04,   4.81910189e-04]], dtype=float32)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submit probas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl_names =['VisitNumber']\n",
    "for cls in rf.classes_:\n",
    "    cl_names.append('TripType_' + str(cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VisitNumber</th>\n",
       "      <th>TripType_3</th>\n",
       "      <th>TripType_4</th>\n",
       "      <th>TripType_5</th>\n",
       "      <th>TripType_6</th>\n",
       "      <th>TripType_7</th>\n",
       "      <th>TripType_8</th>\n",
       "      <th>TripType_9</th>\n",
       "      <th>TripType_12</th>\n",
       "      <th>TripType_14</th>\n",
       "      <th>...</th>\n",
       "      <th>TripType_36</th>\n",
       "      <th>TripType_37</th>\n",
       "      <th>TripType_38</th>\n",
       "      <th>TripType_39</th>\n",
       "      <th>TripType_40</th>\n",
       "      <th>TripType_41</th>\n",
       "      <th>TripType_42</th>\n",
       "      <th>TripType_43</th>\n",
       "      <th>TripType_44</th>\n",
       "      <th>TripType_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.203675e-05</td>\n",
       "      <td>4.272268e-06</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.009562</td>\n",
       "      <td>0.015328</td>\n",
       "      <td>0.011489</td>\n",
       "      <td>6.573525e-04</td>\n",
       "      <td>3.776230e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.331435e-04</td>\n",
       "      <td>1.088904e-03</td>\n",
       "      <td>0.301934</td>\n",
       "      <td>6.305782e-02</td>\n",
       "      <td>2.870736e-04</td>\n",
       "      <td>6.547401e-03</td>\n",
       "      <td>0.009046</td>\n",
       "      <td>2.917252e-03</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.024591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.257572e-05</td>\n",
       "      <td>2.380467e-05</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.049258</td>\n",
       "      <td>0.043971</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>2.088601e-03</td>\n",
       "      <td>1.009277e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.284032e-03</td>\n",
       "      <td>1.154415e-03</td>\n",
       "      <td>0.037092</td>\n",
       "      <td>7.990259e-02</td>\n",
       "      <td>1.633226e-04</td>\n",
       "      <td>2.516618e-03</td>\n",
       "      <td>0.010685</td>\n",
       "      <td>5.446861e-03</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.007468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.990376e-07</td>\n",
       "      <td>9.665358e-08</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>7.759482e-07</td>\n",
       "      <td>1.869699e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.400890e-04</td>\n",
       "      <td>1.323068e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.095897e-06</td>\n",
       "      <td>7.616079e-07</td>\n",
       "      <td>9.969655e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>5.931669e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.999633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.588964e-04</td>\n",
       "      <td>1.209551e-05</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.009547</td>\n",
       "      <td>0.097613</td>\n",
       "      <td>0.797570</td>\n",
       "      <td>4.851065e-05</td>\n",
       "      <td>3.610074e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.519841e-04</td>\n",
       "      <td>7.419621e-05</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>2.430175e-04</td>\n",
       "      <td>5.264738e-05</td>\n",
       "      <td>8.953391e-05</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>9.658957e-05</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.039259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>3.410809e-07</td>\n",
       "      <td>5.584445e-08</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>6.882497e-07</td>\n",
       "      <td>1.586814e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>7.422587e-07</td>\n",
       "      <td>3.658921e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.353922e-07</td>\n",
       "      <td>4.810268e-07</td>\n",
       "      <td>1.885560e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.780883e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.999824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VisitNumber    TripType_3    TripType_4  TripType_5  TripType_6  \\\n",
       "0            1  1.203675e-05  4.272268e-06    0.000145    0.000210   \n",
       "1            2  5.257572e-05  2.380467e-05    0.000299    0.000760   \n",
       "2            3  1.990376e-07  9.665358e-08    0.000003    0.000002   \n",
       "3            4  1.588964e-04  1.209551e-05    0.000631    0.000237   \n",
       "4            6  3.410809e-07  5.584445e-08    0.000001    0.000001   \n",
       "\n",
       "   TripType_7  TripType_8  TripType_9   TripType_12   TripType_14  \\\n",
       "0    0.009562    0.015328    0.011489  6.573525e-04  3.776230e-06   \n",
       "1    0.049258    0.043971    0.004430  2.088601e-03  1.009277e-05   \n",
       "2    0.000063    0.000087    0.000014  7.759482e-07  1.869699e-08   \n",
       "3    0.009547    0.097613    0.797570  4.851065e-05  3.610074e-05   \n",
       "4    0.000038    0.000013    0.000035  6.882497e-07  1.586814e-08   \n",
       "\n",
       "       ...        TripType_36   TripType_37  TripType_38   TripType_39  \\\n",
       "0      ...       5.331435e-04  1.088904e-03     0.301934  6.305782e-02   \n",
       "1      ...       2.284032e-03  1.154415e-03     0.037092  7.990259e-02   \n",
       "2      ...       1.400890e-04  1.323068e-06     0.000003  3.095897e-06   \n",
       "3      ...       3.519841e-04  7.419621e-05     0.000467  2.430175e-04   \n",
       "4      ...       7.422587e-07  3.658921e-07     0.000002  9.353922e-07   \n",
       "\n",
       "    TripType_40   TripType_41  TripType_42   TripType_43  TripType_44  \\\n",
       "0  2.870736e-04  6.547401e-03     0.009046  2.917252e-03     0.000522   \n",
       "1  1.633226e-04  2.516618e-03     0.010685  5.446861e-03     0.000242   \n",
       "2  7.616079e-07  9.969655e-07     0.000004  5.931669e-07     0.000001   \n",
       "3  5.264738e-05  8.953391e-05     0.000948  9.658957e-05     0.000075   \n",
       "4  4.810268e-07  1.885560e-06     0.000009  3.780883e-07     0.000001   \n",
       "\n",
       "   TripType_999  \n",
       "0      0.024591  \n",
       "1      0.007468  \n",
       "2      0.999633  \n",
       "3      0.039259  \n",
       "4      0.999824  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.DataFrame(columns=cl_names)\n",
    "submit['VisitNumber'] = featured_test['VisitNumber']\n",
    "submit[cl_names[1:]] = submit_XGB\n",
    "submit[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.to_csv('submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
